#!/usr/bin/env python3
"""
AI Test Case Generator
Tá»± Ä‘á»™ng táº¡o test case manual chuáº©n theo yÃªu cáº§u sá»­ dá»¥ng AI
"""

import os
import json
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from pathlib import Path

import openai
import anthropic
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

console = Console()

@dataclass
class TestCase:
    """Test Case data structure"""
    test_case_id: str
    test_scenario: str
    test_case_name: str
    test_steps: str
    expected_result: str
    actual_result: str = ""
    status: str = "Not Executed"
    priority: str = "Medium"
    test_type: str = "Functional"
    preconditions: str = ""
    test_data: str = ""
    notes: str = ""

class AITestCaseGenerator:
    """AI-powered Test Case Generator"""

    def __init__(self, ai_provider: str = "openai"):
        self.ai_provider = ai_provider
        self.client = self._initialize_client()

    def _initialize_client(self):
        """Initialize AI client based on provider"""
        if self.ai_provider == "openai":
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY not found in environment variables")
            return openai.OpenAI(api_key=api_key)
        elif self.ai_provider == "anthropic":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY not found in environment variables")
            return anthropic.Anthropic(api_key=api_key)
        else:
            raise ValueError(f"Unsupported AI provider: {self.ai_provider}")

    def generate_test_cases(self, requirement: str, test_types: List[str] = None) -> List[TestCase]:
        """
        Generate test cases using AI based on requirements

        Args:
            requirement: User requirement description
            test_types: List of test types to generate (functional, ui, api, etc.)

        Returns:
            List of generated TestCase objects
        """
        if test_types is None:
            test_types = ["functional", "negative", "edge_case", "regression"]

        all_test_cases = []

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            for test_type in test_types:
                task = progress.add_task(f"Generating {test_type} test cases...", total=1)

                prompt = self._create_prompt(requirement, test_type)
                response = self._call_ai_api(prompt)

                test_cases = self._parse_ai_response(response, test_type)
                all_test_cases.extend(test_cases)

                progress.update(task, completed=1)

        return all_test_cases

    def _create_prompt(self, requirement: str, test_type: str) -> str:
        """Create AI prompt for test case generation"""
        base_prompt = f"""
        Báº¡n lÃ  chuyÃªn gia QA senior. HÃ£y táº¡o test cases manual chuáº©n cho requirement sau:

        REQUIREMENT: {requirement}

        TEST TYPE: {test_type.upper()}

        YÃŠU Cáº¦U:
        - Táº¡o 3-5 test cases cho loáº¡i {test_type}
        - Má»—i test case pháº£i cÃ³:
          * Test Case ID (format: TC_{test_type.upper()}_001, etc.)
          * Test Scenario: MÃ´ táº£ tÃ¬nh huá»‘ng test
          * Test Case Name: TÃªn ngáº¯n gá»n, rÃµ rÃ ng
          * Test Steps: CÃ¡c bÆ°á»›c thá»±c hiá»‡n (Ä‘Ã¡nh sá»‘ 1, 2, 3...)
          * Expected Result: Káº¿t quáº£ mong Ä‘á»£i
          * Preconditions: Äiá»u kiá»‡n tiÃªn quyáº¿t (náº¿u cÃ³)
          * Test Data: Dá»¯ liá»‡u test cáº§n thiáº¿t
          * Priority: High/Medium/Low
        - Test cases pháº£i cover Ä‘áº§y Ä‘á»§ requirement
        - Sá»­ dá»¥ng ngÃ´n ngá»¯ tiáº¿ng Viá»‡t

        FORMAT OUTPUT: JSON array cá»§a objects, má»—i object cÃ³ cÃ¡c trÆ°á»ng trÃªn.
        """

        return base_prompt.strip()

    def _call_ai_api(self, prompt: str) -> str:
        """Call AI API to generate test cases"""
        try:
            if self.ai_provider == "openai":
                response = self.client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia QA táº¡o test cases chuáº©n."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.7
                )
                return response.choices[0].message.content

            elif self.ai_provider == "anthropic":
                response = self.client.messages.create(
                    model="claude-3-sonnet-20240229",
                    max_tokens=2000,
                    system="Báº¡n lÃ  chuyÃªn gia QA táº¡o test cases chuáº©n.",
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                return response.content[0].text

        except Exception as e:
            console.print(f"[red]Error calling AI API: {e}[/red]")
            raise

    def _parse_ai_response(self, response: str, test_type: str) -> List[TestCase]:
        """Parse AI response into TestCase objects"""
        try:
            # Clean response if needed
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.endswith("```"):
                response = response[:-3]

            # Parse JSON
            test_cases_data = json.loads(response)

            test_cases = []
            for i, tc_data in enumerate(test_cases_data, 1):
                # Ensure required fields exist
                tc_data.setdefault('test_case_id', f"TC_{test_type.upper()}_{i:03d}")
                tc_data.setdefault('status', 'Not Executed')
                tc_data.setdefault('test_type', test_type.title())
                tc_data.setdefault('priority', 'Medium')

                test_case = TestCase(**tc_data)
                test_cases.append(test_case)

            return test_cases

        except json.JSONDecodeError as e:
            console.print(f"[red]Error parsing AI response: {e}[/red]")
            console.print(f"[yellow]Response: {response}[/yellow]")
            return []

    def export_to_excel(self, test_cases: List[TestCase], filename: str = None) -> str:
        """
        Export test cases to Excel file

        Args:
            test_cases: List of TestCase objects
            filename: Output filename (optional)

        Returns:
            Path to created Excel file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"test_cases_{timestamp}.xlsx"

        # Convert to DataFrame
        data = []
        for tc in test_cases:
            tc_dict = asdict(tc)
            data.append(tc_dict)

        df = pd.DataFrame(data)

        # Reorder columns for better readability
        columns_order = [
            'test_case_id', 'test_scenario', 'test_case_name', 'preconditions',
            'test_steps', 'test_data', 'expected_result', 'actual_result',
            'status', 'priority', 'test_type', 'notes'
        ]

        # Only include columns that exist
        existing_columns = [col for col in columns_order if col in df.columns]
        df = df[existing_columns]

        # Create Excel writer with formatting
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Test Cases', index=False)

            # Get workbook and worksheet
            workbook = writer.book
            worksheet = writer.sheets['Test Cases']

            # Set column widths
            for i, col in enumerate(df.columns):
                max_length = max(
                    df[col].astype(str).map(len).max(),
                    len(col)
                )
                worksheet.column_dimensions[chr(65 + i)].width = min(max_length + 2, 50)

            # Style header row
            from openpyxl.styles import Font, PatternFill
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")

            for cell in worksheet[1]:
                cell.font = header_font
                cell.fill = header_fill

        console.print(f"[green]âœ“ Test cases exported to: {filename}[/green]")
        return filename

def main():
    """Main function - Simplified version"""
    console.print("[bold blue]ğŸ¤– AI Test Case Generator[/bold blue]")
    console.print("ğŸš€ Chá»‰ cáº§n nháº­p 1 prompt feature, tá»± Ä‘á»™ng táº¡o test cases chuáº©n & xuáº¥t Excel!\n")

    # Get simple feature prompt
    feature_prompt = console.input("[bold cyan]ğŸ“ Nháº­p feature cáº§n test (vÃ­ dá»¥: 'Ä‘Äƒng nháº­p vá»›i email/password'):[/bold cyan]\n")

    if not feature_prompt.strip():
        console.print("[red]âŒ Error: Feature prompt khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng![/red]")
        return

    # Auto-configure with defaults
    ai_provider = os.getenv("DEFAULT_AI_PROVIDER", "openai")
    default_test_types = os.getenv("DEFAULT_TEST_TYPES", "functional,negative,edge_case")
    test_types = [t.strip() for t in default_test_types.split(",")]

    console.print(f"[dim]ğŸ¤– Sá»­ dá»¥ng AI: {ai_provider.upper()}[/dim]")
    console.print(f"[dim]ğŸ“Š Loáº¡i test: {', '.join(test_types)}[/dim]")

    try:
        # Initialize generator
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            init_task = progress.add_task("ğŸš€ Khá»Ÿi táº¡o AI Generator...", total=1)

            generator = AITestCaseGenerator(ai_provider=ai_provider)

            progress.update(init_task, completed=1)

        # Generate test cases
        console.print(f"\n[bold yellow]ğŸ¯ Äang táº¡o test cases cho feature: '{feature_prompt}'[/bold yellow]")

        test_cases = generator.generate_test_cases(feature_prompt, test_types)

        if not test_cases:
            console.print("[red]âŒ KhÃ´ng thá»ƒ táº¡o test cases. Vui lÃ²ng kiá»ƒm tra API key vÃ  thá»­ láº¡i.[/red]")
            return

        console.print(f"[green]âœ… ÄÃ£ táº¡o thÃ nh cÃ´ng {len(test_cases)} test cases![/green]")

        # Auto export to Excel
        console.print("[bold yellow]ğŸ“Š Äang xuáº¥t file Excel...[/bold yellow]")
        excel_file = generator.export_to_excel(test_cases)

        # Summary with celebration
        console.print("
[bold green]ğŸ‰ HOÃ€N THÃ€NH! TEST CASES ÄÃƒ Sáº´N SÃ€NG:[/bold green]"        console.print(f"ğŸ“‹ Tá»•ng sá»‘ test cases: [bold]{len(test_cases)}[/bold]")
        console.print(f"ğŸ¯ Feature: [bold]{feature_prompt}[/bold]")
        console.print(f"ğŸ“ File Excel: [bold]{excel_file}[/bold]")

        # Show sample test case
        if test_cases:
            console.print("
[bold cyan]ğŸ’¡ VÃ Dá»¤ TEST CASE:[/bold cyan]"            tc = test_cases[0]
            console.print(f"ğŸ†” ID: [bold]{tc.test_case_id}[/bold]")
            console.print(f"ğŸ“ TÃªn: [bold]{tc.test_case_name}[/bold]")
            console.print(f"â­ Æ¯u tiÃªn: [bold]{tc.priority}[/bold]")
            console.print(f"ğŸ”§ Loáº¡i: [bold]{tc.test_type}[/bold]")

        console.print("
[dim]ğŸ’¡ Máº¹o: Má»Ÿ file Excel Ä‘á»ƒ xem Ä‘áº§y Ä‘á»§ test cases chi tiáº¿t![/dim]"    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        console.print("[yellow]ğŸ’¡ Kiá»ƒm tra: API key cÃ³ Ä‘Ãºng khÃ´ng? Káº¿t ná»‘i internet á»•n khÃ´ng?[/yellow]")

if __name__ == "__main__":
    main()
